\documentclass[a4paper,12pt,titlepage]{report}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{mathtools,amssymb,amsthm}
\usepackage[top=20mm, bottom=25mm, left=15mm, right=15mm]{geometry}
\usepackage{hyperref}
\usepackage{xcolor}

\newcommand{\octave}{\textit{Octave }}

\setcounter{secnumdepth}{3}
\renewcommand{\thesection}{\arabic{section}.}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}
%\titleformat{\subsubsection}[runin]{\normalfont\bfseries}{\thesubsubsection}{0em}{}

\setlength{\parskip}{0.5em}

\title{Second Rapport d'Avancement Projet Signal\\Reconnaissance Optique de Caractères}
\author{Tristan DRUSSEL - Florian POUTHIER \\ \\ Génie Électrique - 4ème année\\ INSA Strasbourg}
\date{Année scolaire 2019-2020}

\begin{document}
	\begin{titlepage}
		\maketitle
	\end{titlepage}
	\tableofcontents
	\newpage
	\section{Introduction}
	
	\vspace{-0.5em}
	
		Dans le cadre du cours de signal dispensé au semestre 8 de la formation en Génie Électrique, nous devons réaliser un projet utilisant les compétences et connaissances acquises dans le cours mais aussi les approfondir dans le domaine qui concerne notre sujet.
		
		Notre sujet est la \textit{Reconnaissance Optique de Caractères (ROC)}. Ce sujet a déjà été très largement étudié par le passé, et notamment dans de nombreuses thèses visant à développer des outils de conversion d'images vers des données textuelles interprétables ou accessibles informatiquement. La thèse \cite{extr} donne en particulier une bonne introduction aux objectifs premiers de la \textit{ROC} dans le cas de la reconnaissance sur documents scannés. La thèse \cite{mait} permet d'obtenir des informations très intéressantes sur les stratégies de numérisation dans des établissements d'archives comme par exemple la Bibliothèque nationale de France (BnF). D'autres thèses \cite{handrec, chanson} développent des stratégies de reconnaissance de caractères manuscrits dans le cadre de l'étude de textes anciens ou contemporains non informatisés.
		
		Il est indéniable que les domaines d'application des recherches orientées sur la \textit{ROC} sont multiples. Elle est tantôt utilisée dans la reconnaissance d'adresses sur courier postal \cite{ind-post}, tantôt dans la reconnaissance de caractères dans des vidéos \cite{arab-video}, tantôt encore dans la numérisation de textes religieux ou anciens consignés sur papier jusqu'à présent \cite{chanson}.
		
		La \textit{ROC} a également fait l'objet d'approches mathématiques approfondies, tout comme le montre la thèse \cite{line-seg} avec des algoritmes basés sur la segmentation en lignes de documents anciens. Une méthode par apprentissage probabiliste est également exposée dans la thèse \cite{proba}. La thèse \cite{isom} propose quant-à-elle des solutions à la détection d'isomorphismes de graphes en mettant en avant des opérateurs avancés pour l'optimisation des résultats de ces méthodes. Les thèses \cite{handrec, cnn} proposent finalement une utilisation des réseaux de neurones convolutionnels afin de résoudre les problématiques de détections textuelle et faciale.
		
		Nos ambitions vis-à-vis de cet état de l'art sont beaucoup plus modestes et se centreront notamment sur une compréhension et une mise en oeuvre des techniques primitives de \textit{ROC}. \hyperref[objectifs]{Nos objectifs} seront détaillés plus loin. De manière synthétique, nous nous baserons sur les méthodes et les outils de traitement du signal, en vue de pouvoir comparer des caractères et ainsi transformer une photo en un fichier texte numérique. Vous pouvez retrouver l'intégralité de nos codes sur notre dépôt \href{https://github.com/tristanplouz/ProjetSignal}{github ici}.
		
		\vspace{-1em}
		
		\subsection{Une image, un signal?}	
		
		\vspace{-0.5em}
		
		La première des choses à faire est de définir l'image. Une image en informatique est un tableau où l'image est découpée en petits carrés. Chaque case du tableau correspond à un petit carré de l'image et le contenu du tableau est la quantité de rouge, de vert et de bleu de chaque découpage. Plus il y a de découpage plus l'image est précise.
		Afin que l'image devienne un objet mathématique nous pouvons la transformer en une matrice. Le tableau défini précédemment peut donc devenir la matrice suivante:
		\begin{equation}
		\begin{bmatrix} 
		\begin{pmatrix} r_{1,1} \\ g_{1,1}\\ b_{1,1} \end{pmatrix} &\begin{pmatrix} r_{2,1} \\ g_{2,1}\\ b_{2,1} \end{pmatrix}&\begin{pmatrix} r_{3,1} \\ g_{3,1}\\ b_{3,1} \end{pmatrix} 
		\\ \begin{pmatrix} r_{1,2} \\ g_{1,2}\\ b_{1,2} \end{pmatrix} & \begin{pmatrix} r_{2,2} \\ g_{2,2}\\ b_{2,2} \end{pmatrix}&\begin{pmatrix} r_{3,2} \\ g_{3,2}\\ b_{3,2} \end{pmatrix}
		\\ \begin{pmatrix} r_{1,3} \\ g_{1,3}\\ b_{1,3} \end{pmatrix} & \begin{pmatrix} r_{2,3} \\ g_{2,3}\\ b_{2,3} \end{pmatrix}&\begin{pmatrix} r_{3,3} \\ g_{3,3}\\ b_{3,3} \end{pmatrix} 
		\end{bmatrix}
		\end{equation}
		Cette matrice de $ M_{m,n}([0,255]^3)$ permet donc de représenter n'importe quelle image et a autant de coefficients que l'image est décomposée en petites cases.
		Cette écriture est pratique, en effet nous avons accès à chaque proportion de couleur de chaque découpage. En revanche travailler avec des matrices de vecteurs n'est pas chose simple. Nous allons donc transformer cette matrice en une matrice d'éléments de $I=[0,255]$. Pour cela nous avons plusieurs solutions, nous pouvons créer une image en nuance de rouge, on ne prend que la première composante du vecteur de chaque case, en nuance de vert, en prenant la seconde, en nuance de bleu en prenant la dernière ou encore en nuance de gris. Cette dernière s'obtient en faisant la moyenne des scalaires $r$,$g$ et $b$ de chaque vecteur. Nous obtenons donc une matrice de $M_{(m,n)}(I)$:
		\begin{equation}
		\begin{bmatrix} 
		\bar{x} & \bar{x} & \bar{x} 
		\\  \bar{x} & \bar{x} & \bar{x} 
		\\  \bar{x} & \bar{x} & \bar{x}
		\end{bmatrix}
		\end{equation}
		Nous obtenons donc une matrice plus simplement exploitable avec les techniques de traitement du signal.
		\subsection{La corrélation}
		La \textbf{corrélation} est une fonction mathématique qui mesure le degré de ressemblance entre un signal original et une version translatée et/ou bruitée de celui ci. On peut définir cette fonction par la relation suivante:
		\begin{equation}
			C(\tau)=\int_{-\infty}^{+\infty}s(t)r(t-\tau)dt \text{ avec s et r signaux quelconque}
		\end{equation}
		Nous pouvons traduire cette expression pour des signaux discrets.
		\begin{equation}
			C(n)=\sum_{k = -\infty}^{+\infty}s(k)r(k-n)	
		\end{equation}
		Ou pour un signal discret mais borné.
		\begin{equation}
			C(n)=\sum_{k = 0}^{x}s(k)r(k-n)	\text{ le signal borné entre 0 et x} 
		\end{equation}		
		Ces deux définitions sont valables pour des signaux à une dimension comme des signaux temporels. Nos images sont des signaux bidimensionnels avec une variation en $x$ et en $y$.
		\begin{equation}
			C(x,y)=\sum_{x,y} I_1(n,k)I_2(n-x,k-y) \text{ avec }I_1, I_2 \text{ les images}
		\end{equation}
		En calculant les coefficients de corrélation pour toutes les possibilités, nous pouvons déterminer les "endroits" où les deux signaux se ressemblent le plus.
		Les commandes \octave permettant de calculer ces coefficients sont:
		\begin{itemize}
		\item[$\bullet$] \texttt{corr2}, du paquet \texttt{image}, permettant de calculer les coefficients entre deux images ;
		\item[$\bullet$] \texttt{xcorr2}, du paquet \texttt{signal}, permettant de calculer la corrélation 2D entre deux matrices ;
		\item[$\bullet$] \texttt{normxcorr2}, du paquet \texttt{image}, permettant de calculer les coefficients de corrélation normalisés entre deux images. 
		\end{itemize}		
		La corrélation est un outil fonctionnant beaucoup mieux sur des signaux à valeurs moyennes nulles.
		\subsection{Nos objectifs}
		\label{objectifs}
		Avant de commencer le projet, nous avons défini des objectifs assez modestes que nous espérons atteindre. Nous souhaitons partir d'une image à fond uni de n'importe quelle taille contenant du texte dans une certaine police. Nous allons travailler avec la police \texttt{Bitstream Vera Sans Mono}. Il s'agit d'une police monospace, cela signifie que chaque caractère fait la même largeur.
		
		\begin{figure}[h]
			\begin{center}
				\includegraphics[scale=0.15]{../../Data/poesie.png}
			\end{center}
			\begin{center}
				\begin{tabular}{cc}
					\includegraphics[scale=0.2]{../../Data/fullpage_2.png} &
					\includegraphics[scale=0.2]{../../Data/lorem.png}
				\end{tabular}
			\end{center}
			\vspace{-1.5em}
			\caption{Différentes extraits de textes en police \texttt{Bitstream Vera Sans Mono}}
		\end{figure}
		
Ainsi en partant de ces images, il faudra obtenir le texte contenu. Nous verrons les différentes étapes du traitement et nos résultats dans la suite de notre rapport.

		\vspace{-1.5em}
		\section{Solutions}
		\vspace{-1em}
		\subsection{Premier essai}
		\paragraph*{Nous avons dans un premier temps essayé de travailler sur l'image entière, cette méthode est le contenu du premier rapport d'avancement et des paragraphes ci-dessous. Le second essai est disponible \hyperref[essai2]{page~\pageref*{essai2}}}
				
		Nous allons écrire un script \octave qui permet dans un premier temps de charger un motif et une autre image dans le but de chercher ce motif dans l'image. Nous pouvons décomposer notre script en plusieurs étapes:
		\begin{itemize}
			\item[$\bullet$] charger et mettre en forme les images ;
			\item[$\bullet$] chercher le motif dans l'image ;
			\item[$\bullet$] finalement afficher la localisation.
		\end{itemize}	   
		\subsubsection{L'image}
		\label{image}
		Avant de vouloir exploiter des images, nous devons tous d'abord les créer. Nous allons donc sur un logiciel de dessin numérique et nous créons deux images, un motif et une image contenant une ou plusieurs fois ce motif.
			
		Nous importons les images dans \octave et nous les convertissons en une matrice de matrice, puis nous récupérons ensuite l'image en niveau de gris. La dernière étape avant de pourvoir appliquer l'intercorrélation sur les images est la transformation des signaux en signaux à valeurs moyennes nulles. Nous enlevons alors la valeur moyenne de la matrice à chaque élément.
		
		\begin{figure}
		\begin{center}
		\begin{tabular}{cc}
				\includegraphics[scale=0.15]{../illus/motifm0.png} & \includegraphics[scale=0.4]{../illus/motm0.png}\\
				Motif en niveaux de gris  & Image en niveaux de gris \\
				avec valeur moyenne nulle & avec valeur moyenne nulle\\
		\end{tabular}	
		\end{center}
		\vspace{-1em}
		\caption{Motif et image sur lesquels seront appliqués les calculs d'intercorrélation}
		\end{figure}

		\subsubsection{La recherche}
		Maintenant que nos images sont prêtes on peut commencer à chercher le motif dans l'image. Pour cela nous allons utiliser l'intercorrélation. En calculant les coefficients de corrélation entre les deux images, on va pouvoir localiser où le motif original a été translaté horizontalement ou verticalement.
		Sur \octave nous utilisons la fonction \texttt{normxcorr2} afin d'obtenir les coefficients de corrélation normalisés. Cette fonction renvoie une matrice, d'une taille supérieure à l'image, contenant les coefficients d'intercorrélation. Plus le coefficient est proche de 1, plus le motif est semblable à la partie de l'image analysée.
		Nous pouvons représenter cette matrice sur un graphe et ainsi repérer les points de similitude.
		
		\begin{figure}[h]
		\begin{center}
			\begin{tabular}{cc}
				\includegraphics[scale=0.19]{../illus/cor.png} & \includegraphics[scale=0.19]{../illus/cor1.png}\\
				Représentation des coefficients en 3D  & Représentation des coefficients vue de dessous\\
			\end{tabular}
		\end{center}
		\vspace{-1em}
		\caption{Représentations graphiques des résultats d'intercorrélation}
		\end{figure}
		
		Avec ces représentations, nous pouvons repérer les occurrences du motif dans l'image. Il faut maintenant récupérer les coordonnées des pics les plus hauts pour localiser le motif.
		\subsubsection{L'affichage}
		Dans la première partie de réalisation de ce projet, nous avons choisi de localiser les caractères recherchés et de représenter cette localisation. Nous avons donc décidé de dessiner un cercle autour des motifs repérés dans l'image.
		Ainsi après l'exécution du script, le dernier graphique affiché correspond à l'image en niveau de gris où des cercles sont tracés afin d'indiquer les points de similitude entre l'image et le motif.
		Afin de placer les cercles, nous parcourons la matrice de corrélation et nous récupérons les coordonnées de chaque point supérieur à un seuil donné. 

		\subsubsection{Problèmes restants}
		Après différents essais, nous pouvons montrer que certains problèmes persistent et seront à traiter par la suite.
		En effet, si la matrice représentant le motif à chercher n'est pas de la même taille que le motif dans l'image, la corrélation ne trouvera aucune correspondance. Pour résoudre ce problème, il faudra identifier la taille d'un caractère présent dans l'image pour faire correspondre la taille du motif.
		Avec notre technique actuelle, plusieurs points se situent au dessus de notre seuil, c'est pour cela que plusieurs cercles sont tracés pour chaque caractère reconnu. Résoudre ce problème se résumerait à identifier les points proches pour les "rassembler" en une seul occurrence du caractère.
	\subsection{Second essai}
	\label{essai2}
	Après avoir essayé de corriger les problèmes développé ci-dessus, nous avons décidé d'effectuer des changements dans l’algorithme du fonctionnement de base de notre script. Au lieu de travailler sur toute l'image, on découpe l'image en tuiles contenant chacune un caractère, ainsi on applique la corrélation entre le motif et la tuile pour déterminer le caractère contenu dans la tuile.
	
	\begin{figure}[h]
		\begin{center}
			\includegraphics[scale=0.4]{../illus/tuiles.png}
		\end{center}
		\vspace{-1em}
		\caption{Découpage préalable de l'image en tuiles avant les calculs de corrélation}
	\end{figure}

	On fait ensuite défiler nos motifs au dessus de chaque tuile pour trouver la meilleure correspondance.
	Le travail à effectuer se décompose en plusieurs étapes:
		\begin{itemize}
			\item[$\bullet$] charger et mettre en forme les images ;
			\item[$\bullet$] déterminer la taille des tuiles et le nombre de celle ci
			\item[$\bullet$] détecter le caractère présent
		\end{itemize}
	\subsubsection{L'image}
	Pour ce second essai, nous avons gardé les mêmes sources d'images que lors du premier essai en les modifiant légèrement (changement de tailles et de couleurs). Nous appliquons ensuite le même protocole, \hyperref[image]{comme détaillé ici}, de mise en forme, passage en niveau de gris, retrait de la valeur moyenne, etc... 
	\subsubsection{Détermination de la taille des tuiles}
	Plusieurs méthodes étaient possibles pour déterminer la taille des tuiles, nous avons dans un premier temps utilisé la taille des motifs pour déterminer la taille des caractères sur l'image à décoder, cette méthode est très performante mais ne permet pas de gérer des caractères de tailles différentes, en effet les valeurs sont liées dans le processus. Nous nous sommes donc basé sur les espaces inter-caractères. En effet entre chaque caractère une petite espace est présente, la police étant une police monospace, la taille des caractères est identique et ils sont donc tous alignés sur une "grille". Cette espace est détectable, en effet en faisant la moyenne des valeurs sur la colonne on peut identifier les écarts.
	
	\begin{figure}[h]
		\begin{center}
			\includegraphics[scale=0.4]{../illus/detectionSpace.png}
		\end{center}
		\vspace{-1em}
		\caption{Identification graphique des écarts}
	\end{figure}

	Ainsi en comptant le nombre d'espaces détectées nous pouvons déterminer le nombre de caractères par ligne.
	On effectue le même processus, en faisant la moyenne sur les lignes pour détecter le nombre de lignes.
	Il faut ensuite faire attention aux faux écarts, induits par les points et accents sur les lignes et par les espaces sur les colonnes.
	Le système rencontre quelques soucis sur les espaces et les points sur les "i".
	\subsubsection{Détermination du caractère}
	Maintenant qu'on a isolé chaque caractère de l'image dans une tuile, on peut déterminer le caractère présent sur celle-ci. En calculant l'intercorrélation de la tuile et de chaque lettre et en relevant le maximum, on peut déterminer le caractère en présence.

	La \textsc{Figure \ref{cor_dif}} montre le cas où les deux caractères ne sont pas identiques ; le maximum de corrélation est donc aux alentours de 0.4.
	
	La \textsc{Figure \ref{cor_idt}} montre le cas où les deux caractères sont identiques ; le maximum de corrélation est donc aux alentours de 0.9.
	
	\newpage
	
	\begin{figure}[h!]
		\begin{center}	
			\begin{tabular}{cc}
			\includegraphics[scale=0.12]{../illus/tuilev.png} &
			\includegraphics[scale=0.18]{../illus/2echv.png}	\\
			Tuile retenue & Echantillon utilisé	\\	
			\end{tabular}\\
			\includegraphics[scale=0.22]{../illus/2corv.png}
		\end{center}
		\vspace{-2em}
		\caption{Résultats d'un calcul de corrélation entre une tuile et un échantillon identiques}
		\label{cor_idt}
	\end{figure}

	\vspace{2.5em}

	\begin{figure}[h!]
		\begin{center}
			\begin{tabular}{cc}
			\includegraphics[scale=0.12]{../illus/tuile.png} &
			\includegraphics[scale=0.18]{../illus/2ech.png} \\	
			Tuile retenue & Echantillon utilisé		\\		
			\end{tabular}\\
			\includegraphics[scale=0.22]{../illus/2cor.png}
		\end{center}
		\vspace{-2em}
		\caption{Résultats d'un calcul de corrélation entre une tuile et un échantillon différents}
		\label{cor_dif}
	\end{figure}

	\subsubsection{Améliorations apportées au script de base}
	\vspace{-1em}
	Nous avons commencé par écrire le script réalisant les fonctions basiques, puis nous avons ensuite ajouté différentes fonctionnalités pour améliorer notre script.
	\vspace{-1em}
	\paragraph{Ajout d'autres caractères}
	Nos premiers essais se contentaient de la détection des lettres capitales, très petites portions des caractères fréquemment utilisés dans les textes. Nous avons donc augmenté la gamme de caractères disponibles en ajoutant notamment la ponctuation et les minuscules.	
	\paragraph{Détection des marges} 
	En effet, l'image n'est pas forcément uniquement du texte, qui commence dès la première colonne et se termine à la dernière et de même pour les lignes.
	Nous allons donc prévoir le retrait des marges aux bords de l'image, pour cela nous cherchons les premières lignes et colonnes non vides, en extrayant l'image contenue entre la première et dernière ligne et la première et dernière colonne non vide. On détecte les lignes et les colonnes non vides en calculant la valeur moyenne de la colonne. Si la valeur moyenne de la colonne est différente de la précédente, on est donc sur la première colonne non vide. De même pour les colonnes et pour détecter les dernières on part de la fin et on recule.
	Cette méthode fonctionne car nos images sont à fond uni.
	\paragraph{Taille des caractères}
	Avec la méthode de comptage des caractères s'appuyant sur les espaces présents entre les caractères, nous déterminons un nombre de caractère, en divisant la taille de l'image par ce nombre de caractères ou de lignes, nous pouvons déterminer la "surface" d'un caractère. Nos caractères dans la base de données sont d'une très grande taille, comme cela, nous pouvons les redimensionner pour qu'ils correspondent à la taille des caractères de l'image à analyser.
	\paragraph{Rapidité}
	Une fois l'algorithme de détection de caractères suffisamment robuste sur plusieurs exemples d'images, nous avons réfléchi à de nouvelles stratégies afin d'améliorer le temps de détection sur une image complète.
	En effet, le temps de calcul de la corrélation dépend uniquement de la taille des images, si elles sont plus petites (en nombre de pixel) le calcul se fera plus vite. Nous ne pouvons pas attendre une accélération à ce niveau là, nous avons donc agit sur d'autres points.
	\subparagraph{Arrêt de recherche corrélative sur prédiction de maximum}
	\label{stop_cor}
	Une des premières pistes d'amélioration du temps de détection est de prédire un maximum suite à un résultat de corrélation. Cette méthode est très facilement implémentable. Suite au calcul d'une corrélation, si le résultat de cette corrélation est supérieur à une certaine valeur seuil, alors on suppose qu'il n'y aura pas d'autres résultats de corrélation supérieurs à celui-ci. Cette structure réside en une instruction \texttt{if} testant la comparaison du résultat de corrélation avec une valeur seuil variant entre 0.8 et 0.9. Si la comparaison est validée, alors on exécute un \texttt{break} afin de sortir de la boucle de recherche corrélative. Cette solution a l'avantage d'accélérer la recherche en passant plus rapidement à l'analyse de la tuile suivante.
	
	\subparagraph{Recherche corrélative suivant le rang des fréquences d’occurrences de caractères}	 
	 Une autre piste de gain de temps a été de considérer l'aspect linguistique d’occurrences statistiques des caractères dans des textes de la langue française. Le but était alors de tester la corrélation sur chaque tuile en considérant successivement les caractères du plus au moins répandu dans la langue française plutôt que l'ordre alphabétique traditionnel. Pour ce faire, une courte recherche bibliographique nous a amené sur le site web de typographie \textit{Bépo} qui propose un \href{http://bepo.fr/wiki/Fr%C3%A9quence_des_caract%C3%A8res}{\textcolor{blue}{classement des occurences de caractères}} basé sur le corpus Wikipedia français de 2008. La \textsc{Table \ref{freq_carac}} présente cette répartition des occurences. 
	 
\newpage

\begin{table}[h!]
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Rang} & \textbf{Caractère} & \textbf{Nb d'occurrences} & \textbf{\%} \\
\hline
1 &	e &	115 024 205 & 12,1 \\
\hline
2 &	a &	67 563 628 & 7,11 \\
\hline
3 &	i &	62 672 992 & 6,59 \\
\hline
4 &	s &	61 882 785 & 6,51 \\
\hline
5 &	n &	60 728 196 & 6,39 \\
\hline
6 &	r &	57 656 209 & 6,07 \\
\hline
7 &	t &	56 267 109 & 5,92 \\
\hline
8 &	o &	47 724 400 & 5,02 \\
\hline
9 &	l &	47 171 247 & 4,96 \\
\hline
10 & u & 42 698 875 & 4,49 \\
\hline
11 & d & 34 914 685 & 3,67 \\
\hline
12 & c & 30 219 574 & 3,18 \\
\hline
13 & m & 24 894 034 & 2,62 \\
\hline
14 & p & 23 647 179 & 2,49 \\
\hline
15 & é & 18 451 937 & 1,94 \\
\hline
16 &   & 14 847 201 & 1,56 \\
\hline
17 & g & 11 684 140 & 1,23 \\
\hline
18 & b & 10 817 171 & 1,14 \\
\hline
19 & v & 10 590 858 & 1,11 \\ 
\hline
20 & h & 10 583 562 & 1,11 \\ 
\hline
21 & f & 10 579 192 & 1,11 \\
\hline
22 & , &  9 656 092 & 1,02 \\
\hline
23 & 1 &  9 005 786 & 0,95 \\
\hline
24 & . &  7 843 682 & 0,83 \\
\hline
25 & ' &  7 209 956 & 0,76 \\
\hline
26 & 0 &  6 358 672 & 0,67 \\
\hline
27 & 9 &  6 340 285 & 0,67 \\
\hline
28 & q &  6 140 307 & 0,65 \\
\hline
29 & - &  5 718 628 & 0,6  \\
\hline
30 & 2 &  5 462 613 & 0,57 \\
\hline
31 & y &  4 351 953 & 0,46 \\
\hline
32 & 8 &  3 643 296 & 0,38 \\
\hline
33 & ) &  3 638 248 & 0,38 \\
\hline
34 & ( &  3 624 542 & 0,38 \\
\hline
35 & x &  3 588 990 & 0,38 \\
\hline
36 & 3 &  3 459 061 & 0,36 \\
\hline
37 & 5 &  3 396 449 & 0,36 \\
\hline
38 & 6 &  3 376 188 & 0,36 \\
\hline
39 & 4 &  3 326 019 & 0,35 \\ 
\hline
40 & j &  3 276 064 & 0,34 \\
\hline
41 & 7 &  3 244 260 & 0,34 \\
\hline
42 & : &  3 155 250 & 0,33 \\
\hline
\end{tabular}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Rang} & \textbf{Caractère} & \textbf{Nb d'occurrences} & \textbf{\%} \\
\hline
43 & è &  2 969 466 & 0,31 \\
\hline
44 & à &  2 966 029 & 0,31 \\
\hline
45 & k &  2 747 547 & 0,29 \\
\hline
46 & ? &  2 188 127 & 0,23 \\
\hline
47 & w &  1 653 435 & 0,17 \\
\hline
48 & z &  1 433 913 & 0,15 \\
\hline
49 & ê &	802 211 & 0,08 \\
\hline
50 & " &	759 384 & 0,08 \\
\hline
51 & / &	623 640 & 0,07 \\
\hline
52 & ç &	544 509 & 0,06 \\
\hline
53 & > &	499 481 & 0,05 \\
\hline
54 &\# &	493 596 & 0,05 \\
\hline
55 & < & 	476 762 & 0,05 \\
\hline
56 & · &	429 085 & 0,05 \\
\hline
57 &   &	402 911 & 0,04 \\
\hline
58 & ; &	379 874 & 0,04 \\
\hline
59 & ô &	357 197 & 0,04 \\
\hline
60 & « & 	338 547 & 0,04 \\
\hline
61 & » &	332 970 & 0,04 \\
\hline
62 & â &	320 837 & 0,03 \\
\hline
63 & î & 	280 201 & 0,03 \\
\hline
64 & ] &	243 399 & 0,03 \\
\hline
65 &\{ &	243 170 & 0,03 \\
\hline
66 & [ &	241 191 & 0,03 \\
\hline
67 &\} &	229 128 & 0,02 \\
\hline
68 &$^\circ$&214 463& 0,02 \\
\hline
69 & û &    164 516 & 0,02 \\
\hline
70 & ù &	151 236 & 0,02 \\
\hline
71 & ï &	138 221 & 0,01 \\
\hline
72 & = &	121 994 & 0,01 \\
\hline
73 &\% &	121 163 & 0,01 \\
\hline
74 & + &	109 254 & 0,01 \\
\hline
75 & ! &	104 109 & 0,01 \\
\hline
76 &\_ &	 87 702 & 0,01 \\
\hline
77 & á &	 73 751 & 0,01 \\
\hline
78 &\& &	 67 507 & 0,01 \\
\hline
79 & ü & 	 55 172 & 0,01 \\
\hline
80 &$^2$& 	 54 500 & 0,01 \\
\hline
81 & * &	 54 224 & 0,01 \\
\hline
82 & ë & 	 53 862 & 0,01 \\
\hline
83 & ö & 	 51 020 & 0,01 \\
\hline
84 & í &	 48 391 & 0,01 \\ 
\hline
\end{tabular}
\caption{Fréquences des caractères du corpus Wikipédia de 2008 (source \textit{Bépo})}
\label{freq_carac}
\end{table}	

\newpage

L'aspect intéressant de ce classement est notamment d'inclure les caractères spéciaux et de ponctuation que l'on trouve dans la plupart des textes. Ainsi, nous avons un classement complet sur lequel baser et organiser la recherche corrélative sur chacune des tuiles. Cette méthode est notamment associée à l'\hyperref[stop_cor]{arrêt de recherche corrélative}, qui permet alors de passer plus rapidement aux caractères suivants lorsque le caractère semblant être détecté est un caractère couramment utilisé.

Afin d'implémenter l'utilisation d'un tel classement, nous avons renommé les échantillons de caractères utilisés pour les calculs de corrélation. Pour ce faire nous avons ajouté au nom de chaque échantillon la numérotation du rang qui lui correspond dans la \textsc{Table \ref{freq_carac}}, ce qui permet notamment aux caractères d'être placés dans cet ordre dans le tableau de cellules \texttt{alpha}. Ils seront donc utilisés dans ce même ordre lors du parcours par index croissant dans les boucles de recherches corrélatives.

\subparagraph{Détection des tuiles vides}
Un autre poste de perte de temps était la détection des espaces, en effet aucun caractère ne ressemble à une espace donc il parcourait toute notre base de caractèree afin de ne rien trouver. Pour prévenir la recherche inutile, nous observons la tuile, si celle ci est monochrome, on considère que c'est une espace. Ce calcul est beaucoup plus rapide que faire l'intercorrélation de chaque caractère. Pour cela nous comparons la valeur moyenne et la valeur minimum, plus celles-ci sont proches plus la tuile est vide et donc c'est une espace.

\paragraph{Ajout d'interfaces avec l'utilisateur}
	Les premiers tests avec l'adresse de l'image implémentée "en dur" dans le code sont pratiques mais dès que l'on travaille avec plusieurs images, cela devient embêtant de changer le code à chaque fois. Nous avons donc mis une entrée utilisateur pour sélectionner le fichier à analyser.
	Nous avons aussi rajouter des questions pour le bon et rapide fonctionnement du script, comme la gamme de couleur de l'image (fond foncé ou fond clair) et si le texte ne contient que des majuscules, en effet si c'est le cas, pas besoin de charger et de tester toutes les minuscules.
	Nous avons aussi rajouté une interface utilisateur pour l'informer. Nous avons donc des informations progressivement sur l'avancement du traitement et le temps estimé. Nous avons au final un message résumant toutes les informations:\\
	\texttt{
	Adresse du fichier(Laisser vide pour default)Data/lorem.png\\
Le texte foncé sur fond clair?(yes or no) no\\
Le texte contient uniquement des majuscules?(yes or no) yes\\
Chargement des éléments...\\
Éléments chargés en \\
14.6307s\\
Nombre de caractère détecté:\\
 125\\
Caractère par ligne:\\
 25\\
Nombre de ligne:\\
 5\\
Facteur d'échelle:\\
 0.20559\\
Début de l'analyse...\\
Caractère : 1 sur 125 en 1.1655s (eta 1967.7926s)\\
Caractère : 2 sur 125 en 3.4692s (eta 1189.454s)\\
Caractère : 3 sur 125 en 3.2777s (eta 919.8982s)\\
Caractère : 4 sur 125 en 3.3176s (eta 784.6771s)\\
Caractère : 5 sur 125 en 3.4027s (eta 704.2605s)\\
	...\\
Caractère : 120 sur 125 en 0.002918s (eta 12.2507s)\\
Caractère : 121 sur 125 en 0.003238s (eta 9.7197s)\\
Caractère : 122 sur 125 en 0.002944s (eta 7.2302s)\\
Caractère : 123 sur 125 en 0.0027471s (eta 4.781s)\\
Caractère : 124 sur 125 en 0.0036941s (eta 2.3713s)\\
Caractère : 125 sur 125 en 0.0030529s (eta 0s)\\
Texte extrait de Data/lorem.png en 294.0443:\\
LOREM IPSUM DOLOR SIT AME\\
NULLAM FEUGIAT JUSTO RISU\\
ENIM RHONCUS.PROIN ID PEL\\
LENTESOUE NUNC. PELLENTES\\
OUE EU RUTRUM EX.\\}

	\vspace{-2em}
	\subsection{Résultat Final}
	Une fois que toutes les améliorations ont été implémentées on peut lancer un test massif sur les performances de notre script.
	Pour cela, nous avons créé une image finale représentée en \textsc{Figure \ref{DUDH}}.
	
	\begin{figure}[h]
		\begin{center}
			\includegraphics[scale=0.45]{../../Data/DUDH.png}
		\end{center}
		\vspace{-4em}
		\caption{Création d'une image de validation finale basée sur la \textit{Déclaration des Droits de l'Homme}}
		\label{DUDH}
	\end{figure}
	
	Nous exécutons ensuite le script.
	Dans un premier temps, nous obtenons le découpage en tuiles exposé en \textsc{Figure \ref{tuilesDUDH}}.
	
	Chaque caractère est sur une tuile, on peut donc appliquer l'intercorrelation et trouver chaque caractère.
	Au bout de 11min40s, nous obtenons le résultat montré en \textsc{Figure \ref{diffDUDH}}.
	
	\begin{figure}[ht!]
		\begin{center}
			\includegraphics[scale=0.42]{../illus/tuilesDUDH.png}
		\end{center}
		\vspace{-4em}
		\caption{Découpage en tuiles de l'image précédemment créée}
		\label{tuilesDUDH}
	\end{figure}
	
	\vspace{4em}
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[scale=0.42]{../illus/diffDUDH.png}
		\end{center}
		\vspace{-1em}
		\caption{Comparaison du texte original avec la sortie du script \octave exécuté sur l'image créée}
		\label{diffDUDH}
	\end{figure}
	
	Nous pouvons voir sur la capture du logiciel \textit{Meld} (\textsc{Figure \ref{diffDUDH}}), permettant de réaliser la comparaison de fichiers, que le résultat est totalement satisfaisant, il persiste des erreurs que nous allons maintenant détailler.
	
	\begin{itemize}
		\item[$\bullet$] Dans un premier temps, nous pouvons relever que l'accentuation n'est pas retransmise. Il s'agit là d'un soucis de détection sur le seuil et l'intercorrélation. En effet, les caractères accentués sont des voyelles très présentes dans la langue française, mais le "e" est détecté avant de détecter un "e" accentué. L'autre soucis est que l'accent est en bord de tuiles, ce qui le rend moins facilement détectable, et le maximum de l'image s'effectuera donc plus sur la lettre que sur l'accent.
		\item[$\bullet$] Le second soucis est la ponctuation, et là il s'agit du même soucis, l'intercorrélation ne parvient pas à faire la différence entre une virgule, un point et un point virgule.
		\item[$\bullet$] Le dernier soucis qu'on peut remarquer est la non présence des numéros 4 et 5, alors que les précédents y sont. Cela vient du fait que les chiffres ne sont implémentés dans la base de données que de 0 à 3.
	\end{itemize}
	
	\subsection{Améliorations futures et suites du projet}	
	Maintenant que notre script fonctionne bien, nous pouvons nous concentrer sur les petits détails. Dans un premier temps, inclure les 84 caractères et les classer dans le bon ordre dans la base de données tels qu'ils sont définis ci-dessus, dans leurs versions capitale et minuscule. Cela permettra de "lire" tous les documents possibles. Dans un second temps, pour augmenter la performance du script, il faut trouver un système permettant de reconnaître les caractères accentués ainsi que tous les caractères de ponctuations. De plus, améliorer la détection du nombre de caractères pourra permettre d'augmenter la précision du script, en pouvant prendre en compte les titres et les différents paragraphes.
	
	Une autre voie de poursuite du projet serait l'implémentation d'autres effets de police, comme l'italique, le gras ou le souligné.
	
	On peut aussi essayer d'implémenter un redressement des images. En effet, lorsque l'on prend une photo le texte est rarement correctement aligné, il faut donc corriger un effet de cisaillement sur les images.
	
	L'objectif final du projet pourrait être de partir d'une photo d'un polycopié, écrit avec la bonne police, pour arriver à un fichier texte contenant le texte du document.
	\section{Conclusion}
	Le script que nous avons développé permet aujourd'hui de récupérer le texte contenu dans une image, mais cette image doit répondre à des critères précis. Nous remplissons les objectifs définis au début de notre rapport. L'avenir de ce script sera de diminuer les critères pour que le script fonctionne. En implémentant d'autres outils de traitement du signal, on augmentera les performances du script.
	
	\listoffigures
	
	\listoftables
	
	\bibliographystyle{plain} 
	\bibliography{biblio}
	
\end{document}
